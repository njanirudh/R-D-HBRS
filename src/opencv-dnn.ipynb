{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Labels of Network.\n",
    "classNames = { 0: 'background',\n",
    "    1: 'aeroplane', 2: 'bicycle', 3: 'bird', 4: 'boat',\n",
    "    5: 'bottle', 6: 'bus', 7: 'car', 8: 'cat', 9: 'chair',\n",
    "    10: 'cow', 11: 'diningtable', 12: 'dog', 13: 'horse',\n",
    "    14: 'motorbike', 15: 'person', 16: 'pottedplant',\n",
    "    17: 'sheep', 18: 'sofa', 19: 'train', 20: 'tvmonitor' }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = \"/home/jayasimha/Projects/OpenCV/MobilNet_SSD_opencv-master/img.jpeg\"\n",
    "prototxt_path = \"/home/jayasimha/Projects/OpenCV/MobilNet_SSD_opencv-master/MobileNetSSD_deploy.prototxt\"\n",
    "weights_path = \"/home/jayasimha/Projects/OpenCV/MobilNet_SSD_opencv-master/MobileNetSSD_deploy.caffemodel\"\n",
    "\n",
    "threshold = 0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the Caffe model \n",
    "net = cv2.dnn.readNetFromCaffe(prototxt_path, weights_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load image from the path\n",
    "frame = cv2.imread(img_path)\n",
    "frame_resized = cv2.resize(frame,(300,300)) # resize frame for prediction\n",
    "heightFactor = frame.shape[0]/300.0\n",
    "widthFactor = frame.shape[1]/300.0 \n",
    "# MobileNet requires fixed dimensions for input image(s)\n",
    "# so we have to ensure that it is resized to 300x300 pixels.\n",
    "# set a scale factor to image because network the objects has differents size. \n",
    "# We perform a mean subtraction (127.5, 127.5, 127.5) to normalize the input;\n",
    "# after executing this command our \"blob\" now has the shape:\n",
    "# (1, 3, 300, 300)\n",
    "blob = cv2.dnn.blobFromImage(frame_resized, 0.007843, (300, 300), (127.5, 127.5, 127.5), False)\n",
    "#Set to network the input blob \n",
    "net.setInput(blob)\n",
    "#Prediction of network\n",
    "detections = net.forward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_copy = frame.copy()\n",
    "frame_copy2 = frame.copy()\n",
    "#Size of frame resize (300x300)\n",
    "cols = frame_resized.shape[1] \n",
    "rows = frame_resized.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'args' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-694d1a7ce8f2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdetections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mconfidence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdetections\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m#Confidence of prediction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mconfidence\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthr\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# Filter prediction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0mclass_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdetections\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Class label\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'args' is not defined"
     ]
    }
   ],
   "source": [
    "#For get the class and location of object detected, \n",
    "# There is a fix index for class, location and confidence\n",
    "# value in @detections array .\n",
    "for i in range(detections.shape[2]):\n",
    "    confidence = detections[0, 0, i, 2] #Confidence of prediction \n",
    "    if confidence > args.thr: # Filter prediction \n",
    "        class_id = int(detections[0, 0, i, 1]) # Class label\n",
    "\n",
    "        # Object location \n",
    "        xLeftBottom = int(detections[0, 0, i, 3] * cols) \n",
    "        yLeftBottom = int(detections[0, 0, i, 4] * rows)\n",
    "        xRightTop   = int(detections[0, 0, i, 5] * cols)\n",
    "        yRightTop   = int(detections[0, 0, i, 6] * rows)\n",
    "\n",
    "        xLeftBottom_ = int(widthFactor * xLeftBottom) \n",
    "        yLeftBottom_ = int(heightFactor* yLeftBottom)\n",
    "        xRightTop_   = int(widthFactor * xRightTop)\n",
    "        yRightTop_   = int(heightFactor * yRightTop)\n",
    "        # Draw location of object  \n",
    "        cv2.rectangle(frame_resized, (xLeftBottom, yLeftBottom), (xRightTop, yRightTop),\n",
    "                      (0, 255, 0))\n",
    "\n",
    "        cv2.rectangle(frame_copy, (xLeftBottom_, yLeftBottom_), (xRightTop_, yRightTop_),\n",
    "                      (0, 255, 0),-1)\n",
    "opacity = 0.3\n",
    "cv2.addWeighted(frame_copy, opacity, frame, 1 - opacity, 0, frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person: 0.84372514\n",
      "person: 0.7661178\n"
     ]
    }
   ],
   "source": [
    "for i in range(detections.shape[2]):\n",
    "    confidence = detections[0, 0, i, 2] #Confidence of prediction\n",
    "    if confidence > 0.7 :# Threshold \n",
    "        class_id = int(detections[0, 0, i, 1]) # Class label\n",
    "\n",
    "        # Object location \n",
    "        xLeftBottom = int(detections[0, 0, i, 3] * cols) \n",
    "        yLeftBottom = int(detections[0, 0, i, 4] * rows)\n",
    "        xRightTop   = int(detections[0, 0, i, 5] * cols)\n",
    "        yRightTop   = int(detections[0, 0, i, 6] * rows)\n",
    "\n",
    "        xLeftBottom_ = int(widthFactor * xLeftBottom) \n",
    "        yLeftBottom_ = int(heightFactor* yLeftBottom)\n",
    "        xRightTop_   = int(widthFactor * xRightTop)\n",
    "        yRightTop_   = int(heightFactor * yRightTop)\n",
    "        cv2.rectangle(frame, (xLeftBottom_, yLeftBottom_), (xRightTop_, yRightTop_),\n",
    "          (0, 0, 0),2)\n",
    "        # Draw label and confidence of prediction in frame resized\n",
    "        if class_id in classNames:\n",
    "            label = classNames[class_id] + \": \" + str(confidence)\n",
    "            labelSize, baseLine = cv2.getTextSize(label, cv2.FONT_HERSHEY_TRIPLEX, 0.8, 1)\n",
    "\n",
    "            yLeftBottom_ = max(yLeftBottom_, labelSize[1])\n",
    "            cv2.rectangle(frame, (xLeftBottom_, yLeftBottom_ - labelSize[1]),\n",
    "                                 (xLeftBottom_ + labelSize[0], yLeftBottom_ + baseLine),\n",
    "                                 (255, 255, 255), cv2.FILLED)\n",
    "            cv2.putText(frame, label, (xLeftBottom_, yLeftBottom_),\n",
    "                        cv2.FONT_HERSHEY_TRIPLEX, 0.8, (0, 0, 0))\n",
    "            print(label) #print class and confidence \n",
    "cv2.namedWindow(\"frame\", cv2.WINDOW_NORMAL)\n",
    "cv2.imshow(\"frame\", frame)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
