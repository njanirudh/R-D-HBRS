{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove numpy warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import glob\n",
    "import os\n",
    "import csv\n",
    "from pprint import pprint\n",
    "from pathlib import Path\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mAP\n",
    "\n",
    "Bounding boxes are a crude approximation of many objects. \n",
    "Ground truth boxes :  Box that denote the true position of an object (x,y,width,height).\n",
    "\n",
    "### IoU (Intersection over Union)\n",
    "It is the measure of the ratio between the intersection and the union of the predicted box and the ground truth boxes.[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://tarangshah.com/blog/images/map-7.png\" width=\"300\" height=\"300\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url= \"https://tarangshah.com/blog/images/map-7.png\", width=300, height=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision & Recall\n",
    "\n",
    "True Positive\n",
    "False Positive\n",
    "True Negative\n",
    "False Negative\n",
    "\n",
    "Total Number of Objects\n",
    "\n",
    "Precision : \n",
    "Recall :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_annotation(annotation_path:str):\n",
    "    \"\"\"\n",
    "    Reads the annotation from the XML file \n",
    "    into dictionary.\n",
    "    \"\"\"    \n",
    "    tree = ET.parse(annotation_path)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    all_results = []\n",
    "    for boxes in root.iter('object'):\n",
    "        single_result = {}\n",
    "\n",
    "        filename = root.find('filename').text\n",
    "        class_name = boxes.find('name').text\n",
    "        \n",
    "        ymin, xmin, ymax, xmax = None, None, None, None\n",
    "\n",
    "        for box in boxes.findall(\"bndbox\"):\n",
    "            ymin = int(box.find(\"ymin\").text)\n",
    "            xmin = int(box.find(\"xmin\").text)\n",
    "            ymax = int(box.find(\"ymax\").text)\n",
    "            xmax = int(box.find(\"xmax\").text)\n",
    "\n",
    "        list_with_single_boxes = (xmin, ymin, xmax, ymax)\n",
    "        single_result['label'] = class_name\n",
    "        single_result['bbox'] = list_with_single_boxes\n",
    "        \n",
    "        all_results.append(single_result)\n",
    "\n",
    "    result = {}\n",
    "    result[\"status\"] = True \n",
    "    result[\"results\"] = all_results \n",
    "    \n",
    "    return result\n",
    "\n",
    "# result = read_annotation(\"/home/jayasimha/Pictures/door_2.xml\")\n",
    "# pprint(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ObjDetector():\n",
    "    \"\"\"\n",
    "    Object detector class for running a  \n",
    "    tensorflow detection on an image.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.graph_def = None\n",
    "        self.out = None\n",
    "        self.img = None\n",
    "        self.labels = {}\n",
    "        \n",
    "        self.rows = 0\n",
    "        self.cols = 0\n",
    "    \n",
    "    def initialize_model(self,pb_path:str):\n",
    "        with tf.gfile.GFile(pb_path, 'rb') as f:\n",
    "            self.graph_def = tf.GraphDef()\n",
    "            self.graph_def.ParseFromString(f.read())\n",
    "            \n",
    "    def set_labels(self,path:str):\n",
    "        with open(path, 'r') as csvFile:\n",
    "            reader = csv.reader(csvFile)\n",
    "            for i,row in enumerate(reader):\n",
    "                self.labels[i+1] = row[-1]\n",
    "        csvFile.close()\n",
    "    \n",
    "    def run_detection(self,img_path:str):\n",
    "        with tf.Session() as sess:\n",
    "            # Restore session\n",
    "            sess.graph.as_default()\n",
    "            tf.import_graph_def(self.graph_def, name='')\n",
    "\n",
    "            # Read and preprocess an image.\n",
    "            self.img = cv2.imread(img_path)\n",
    "            self.img = cv2.resize(self.img,(480,640))\n",
    "    \n",
    "            self.rows = self.img.shape[0]\n",
    "            self.cols = self.img.shape[1]\n",
    "            inp = cv2.resize(self.img, (300, 300))\n",
    "            inp = inp[:, :, [2, 1, 0]]  # BGR2RGB\n",
    "\n",
    "            # Run the model\n",
    "            self.out = sess.run([sess.graph.get_tensor_by_name('num_detections:0'),\n",
    "                            sess.graph.get_tensor_by_name('detection_scores:0'),\n",
    "                            sess.graph.get_tensor_by_name('detection_boxes:0'),\n",
    "                            sess.graph.get_tensor_by_name('detection_classes:0')],\n",
    "                           feed_dict={'image_tensor:0': inp.reshape(1, inp.shape[0], inp.shape[1], 3)})\n",
    "            sess.close()\n",
    "\n",
    "        return self\n",
    "                \n",
    "    \n",
    "    def get_result(self):\n",
    "        status = True\n",
    "        \n",
    "        all_results = []\n",
    "        # Visualize detected bounding boxes.\n",
    "        num_detections = int(self.out[0][0])\n",
    "        for i in range(num_detections):\n",
    "            single_result = {}\n",
    "\n",
    "            classId = int(self.out[3][0][i])\n",
    "            score = float(self.out[1][0][i])\n",
    "            bbox = [float(v) for v in self.out[2][0][i]]\n",
    "            if score > 0.3:\n",
    "                x = int(bbox[1] * self.cols)\n",
    "                y = int(bbox[0] * self.rows)\n",
    "                right = int(bbox[3] * self.cols)\n",
    "                bottom = int(bbox[2] * self.rows)\n",
    "                                \n",
    "                single_result['label'] = self.labels[classId]\n",
    "                single_result['bbox'] = (x,y,x+right,y+bottom)\n",
    "                \n",
    "                all_results.append(single_result)\n",
    "                \n",
    "        result = {}\n",
    "        result[\"status\"] = status \n",
    "        result[\"results\"] = all_results\n",
    "    \n",
    "        return result\n",
    "    \n",
    "    def reset():\n",
    "        tf.reset_default_graph()\n",
    "        self.out = None\n",
    "        self.img = None\n",
    "        self.rows = 0\n",
    "        self.cols = 0\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bbox_for_label(json:str,label:str):\n",
    "    result_list = json[\"results\"]\n",
    "    for val in result_list:\n",
    "        if val[\"label\"] == label:\n",
    "            return val[\"bbox\"]\n",
    "        else:\n",
    "            return (0,0,0,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_total_labels(json:str,label:str):\n",
    "    result_list = json[\"results\"]\n",
    "    total_labels = 0\n",
    "    for val in result_list:\n",
    "        if val[\"label\"] == label:\n",
    "            total_labels += 1\n",
    "    \n",
    "    return total_labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bb_intersection_over_union(boxA, boxB):\n",
    "    \"\"\"\n",
    "    Function to calculate the IoU between two bounding boxs.\n",
    "    https://www.pyimagesearch.com/2016/11/07/intersection-over-union-iou-for-object-detection/\n",
    "    \"\"\"\n",
    "    # determine the (x, y)-coordinates of the intersection rectangle\n",
    "    xA = max(boxA[0], boxB[0])\n",
    "    yA = max(boxA[1], boxB[1])\n",
    "    xB = min(boxA[2], boxB[2])\n",
    "    yB = min(boxA[3], boxB[3])\n",
    "\n",
    "    # compute the area of intersection rectangle\n",
    "    interArea = max(0, xB - xA + 1) * max(0, yB - yA + 1)\n",
    "\n",
    "    # compute the area of both the prediction and ground-truth\n",
    "    # rectangles\n",
    "    boxAArea = (boxA[2] - boxA[0] + 1) * (boxA[3] - boxA[1] + 1)\n",
    "    boxBArea = (boxB[2] - boxB[0] + 1) * (boxB[3] - boxB[1] + 1)\n",
    "\n",
    "    # compute the intersection over union by taking the intersection\n",
    "    # area and dividing it by the sum of prediction + ground-truth\n",
    "    # areas - the interesection area\n",
    "    iou = interArea / float(boxAArea + boxBArea - interArea)\n",
    "\n",
    "    # return the intersection over union value\n",
    "    return iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "TF_MODEL_PATH = \"/home/nj/NJ/Models/faster_rcnn_inception_resnet_v2_atrous_oid_v4_2018_12_12/frozen_inference_graph.pb\"\n",
    "MODEL_LABEL_PATH = \"/home/nj/NJ/Models/faster_rcnn_inception_resnet_v2_atrous_oid_v4_2018_12_12/class-descriptions-boxable.csv\"\n",
    "\n",
    "DATASET_PATH = \"/home/nj/Pictures/Datasets/door\" \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_detection_on_dataset(path:str , IOU_threshold : float):\n",
    "    \"\"\"\n",
    "    Runs the detection on a set of images(.jpg) and its annotation(.xml)\n",
    "    \"\"\"\n",
    "    obj_detector = ObjDetector()\n",
    "    obj_detector.initialize_model(TF_MODEL_PATH)\n",
    "    obj_detector.set_labels(MODEL_LABEL_PATH)\n",
    "\n",
    "    img_file_list = glob.glob(os.path.join(DATASET_PATH,\"*.jpg\"), recursive=True)\n",
    "\n",
    "    DOOR_TRUE_POSITIVE , DOOR_FALSE_POSITIVE ,DOOR_TOTAL  = 0 , 0 , 0\n",
    "    HANDLE_TRUE_POSITIVE , HANDLE_FALSE_POSITIVE , HANDLE_TOTAL = 0 , 0 , 0\n",
    "    \n",
    "    for img in img_file_list :\n",
    "        name = Path(img).stem\n",
    "        img_path = os.path.join(path , name + \".jpg\")\n",
    "        annotation_path = os.path.join(path , name + \".xml\")\n",
    "        \n",
    "        detection_result = obj_detector.run_detection(img).get_result()\n",
    "        annotation_result = read_annotation(annotation_path)\n",
    "    \n",
    "#         print(\"Detection : \", detection_result)\n",
    "#         print()\n",
    "#         print(\"Annotation : \",annotation_result)\n",
    "        \n",
    "        # Calculating the total annotated items\n",
    "        # --------------------------------------------------------------\n",
    "        DOOR_TOTAL += get_total_labels(annotation_result,\"door\")\n",
    "        HANDLE_TOTAL += get_total_labels(annotation_result,\"Door handle\") \n",
    "        \n",
    "        # IoU for \"Door\" \n",
    "        # --------------------------------------------------------------\n",
    "        door_detection_bbox = get_bbox_for_label(detection_result,\"Door\")\n",
    "        door_annotation_bbox = get_bbox_for_label(annotation_result,\"door\")\n",
    "    \n",
    "        door_single_IoU = bb_intersection_over_union(door_detection_bbox,door_annotation_bbox)   \n",
    "        if door_single_IoU > IOU_threshold :\n",
    "            DOOR_TRUE_POSITIVE += 1\n",
    "        else:\n",
    "            DOOR_FALSE_POSITIVE += 1\n",
    "    \n",
    "        # IoU for \"Door\" \n",
    "        # --------------------------------------------------------------\n",
    "        handle_detection_bbox = get_bbox_for_label(detection_result,\"Door handle\")\n",
    "        handle_annotation_bbox = get_bbox_for_label(annotation_result,\"Door handle\")\n",
    "    \n",
    "        handle_single_IoU = bb_intersection_over_union(handle_detection_bbox,handle_annotation_bbox)\n",
    "        if handle_single_IoU > IOU_threshold :\n",
    "            HANDLE_TRUE_POSITIVE += 1\n",
    "        else:\n",
    "            HANDLE_FALSE_POSITIVE += 1\n",
    "            \n",
    "        # Image Viewer\n",
    "        # --------------------------------------------------------------\n",
    "        out_img = cv2.imread(img_path)\n",
    "        cv2.rectangle(out_img,(door_detection_bbox[0], door_detection_bbox[1]),\n",
    "                  (door_detection_bbox[2], door_detection_bbox[3]),(255,255,0),2)\n",
    "        cv2.rectangle(out_img,(door_annotation_bbox[0], door_annotation_bbox[1]),\n",
    "                  (door_annotation_bbox[2], door_annotation_bbox[3]),(255,0,0),2)\n",
    "        cv2.rectangle(out_img,(handle_detection_bbox[0], handle_detection_bbox[1]),\n",
    "                  (handle_detection_bbox[2], handle_detection_bbox[3]),(255,255,0),2)\n",
    "        cv2.rectangle(out_img,(door_annotation_bbox[0], door_annotation_bbox[1]),\n",
    "                  (door_annotation_bbox[2], door_annotation_bbox[3]),(255,0,0),2)\n",
    "        \n",
    "    # Door calculations\n",
    "    DOOR_PRECISION  = (DOOR_TRUE_POSITIVE)/(DOOR_TRUE_POSITIVE + DOOR_FALSE_POSITIVE)\n",
    "    DOOR_RECALL = 0.0 if (DOOR_TOTAL == 0) else (DOOR_TRUE_POSITIVE/DOOR_TOTAL)\n",
    "\n",
    "    # Handle calculations\n",
    "    HANDLE_PRECISION = (HANDLE_TRUE_POSITIVE)/(HANDLE_TRUE_POSITIVE + HANDLE_FALSE_POSITIVE)\n",
    "    HANDLE_RECALL = 0.0 if (HANDLE_TOTAL == 0) else (HANDLE_TRUE_POSITIVE/HANDLE_TOTAL)\n",
    "    \n",
    "    # mAP and mAR for the items\n",
    "    mAP = (DOOR_PRECISION + HANDLE_PRECISION)/2\n",
    "    mAR = (DOOR_RECALL + HANDLE_RECALL)/2\n",
    "    \n",
    "    #plt.imshow(out_img)\n",
    "    #plt.show()\n",
    "    return mAP , mAR \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IoU_threshold_start = 0.5\n",
    "PRECISION = []\n",
    "RECALL = []\n",
    "\n",
    "for IoU in np.arange(IoU_threshold_start,1.0,0.05):\n",
    "    mAP , mAR  = run_detection_on_dataset(DATASET_PATH,IoU)\n",
    "    PRECISION.append(mAP)\n",
    "    RECALL.append(mAP)    \n",
    "    \n",
    "    print('---------Model@'+str(IoU)+'----------')\n",
    "    print('mAP of the detection model : ',mAP)\n",
    "    print('mAR of the detection model : ',mAR)\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### References :\n",
    "\n",
    "1. https://tarangshah.com/blog/2018-01-27/what-is-map-understanding-the-statistic-of-choice-for-comparing-object-detection-models/\n",
    "2. https://www.pyimagesearch.com/2016/11/07/intersection-over-union-iou-for-object-detection/\n",
    "3. http://homepages.inf.ed.ac.uk/ckiw/postscript/ijcv_voc09.pdf\n",
    "4. http://cocodataset.org/#detection-eval\n",
    "5. https://stackoverflow.com/questions/53317592/reading-pascal-voc-annotations-in-python\n",
    "6. https://medium.com/@jonathan_hui/map-mean-average-precision-for-object-detection-45c121a31173"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
