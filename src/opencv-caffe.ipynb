{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using OpenCV-DNN for detection using a caffe model\n",
    "# https://github.com/djmv/MobilNet_SSD_opencv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Labels of Network.\n",
    "classNames = { 0: 'background',\n",
    "    1: 'aeroplane', 2: 'bicycle', 3: 'bird', 4: 'boat',\n",
    "    5: 'bottle', 6: 'bus', 7: 'car', 8: 'cat', 9: 'chair',\n",
    "    10: 'cow', 11: 'diningtable', 12: 'dog', 13: 'horse',\n",
    "    14: 'motorbike', 15: 'person', 16: 'pottedplant',\n",
    "    17: 'sheep', 18: 'sofa', 19: 'train', 20: 'tvmonitor' }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = \"/home/jayasimha/Projects/OpenCV/MobilNet_SSD_opencv-master/img.jpeg\"\n",
    "prototxt_path = \"/home/jayasimha/Projects/OpenCV/MobilNet_SSD_opencv-master/MobileNetSSD_deploy.prototxt\"\n",
    "weights_path = \"/home/jayasimha/Projects/OpenCV/MobilNet_SSD_opencv-master/MobileNetSSD_deploy.caffemodel\"\n",
    "\n",
    "threshold = 0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the Caffe model \n",
    "net = cv2.dnn.readNetFromCaffe(prototxt_path, weights_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load image from the path\n",
    "frame = cv2.imread(img_path)\n",
    "frame_resized = cv2.resize(frame,(300,300)) # resize frame for prediction\n",
    "heightFactor = frame.shape[0]/300.0\n",
    "widthFactor = frame.shape[1]/300.0 \n",
    "# MobileNet requires fixed dimensions for input image(s)\n",
    "# so we have to ensure that it is resized to 300x300 pixels.\n",
    "# set a scale factor to image because network the objects has differents size. \n",
    "# We perform a mean subtraction (127.5, 127.5, 127.5) to normalize the input;\n",
    "# after executing this command our \"blob\" now has the shape:\n",
    "# (1, 3, 300, 300)\n",
    "blob = cv2.dnn.blobFromImage(frame_resized, 0.007843, (300, 300), (127.5, 127.5, 127.5), False)\n",
    "#Set to network the input blob \n",
    "net.setInput(blob)\n",
    "#Prediction of network\n",
    "detections = net.forward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_copy = frame.copy()\n",
    "frame_copy2 = frame.copy()\n",
    "#Size of frame resize (300x300)\n",
    "cols = frame_resized.shape[1] \n",
    "rows = frame_resized.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 93, 100, 119],\n",
       "        [109, 116, 135],\n",
       "        [113, 123, 141],\n",
       "        ...,\n",
       "        [233, 229, 240],\n",
       "        [234, 230, 241],\n",
       "        [234, 230, 241]],\n",
       "\n",
       "       [[ 92,  99, 118],\n",
       "        [105, 115, 133],\n",
       "        [112, 122, 140],\n",
       "        ...,\n",
       "        [236, 232, 243],\n",
       "        [236, 232, 243],\n",
       "        [236, 232, 243]],\n",
       "\n",
       "       [[ 87,  97, 114],\n",
       "        [100, 110, 127],\n",
       "        [110, 120, 137],\n",
       "        ...,\n",
       "        [238, 231, 244],\n",
       "        [238, 231, 244],\n",
       "        [238, 231, 244]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 21,  20,   0],\n",
       "        [ 21,  20,   0],\n",
       "        [ 21,  20,   0],\n",
       "        ...,\n",
       "        [128, 114,  86],\n",
       "        [114, 100,  72],\n",
       "        [110,  96,  68]],\n",
       "\n",
       "       [[ 21,  20,   0],\n",
       "        [ 21,  20,   0],\n",
       "        [ 21,  20,   0],\n",
       "        ...,\n",
       "        [134, 118,  89],\n",
       "        [127, 111,  82],\n",
       "        [116, 100,  71]],\n",
       "\n",
       "       [[ 21,  20,   0],\n",
       "        [ 21,  20,   0],\n",
       "        [ 21,  20,   0],\n",
       "        ...,\n",
       "        [137, 121,  92],\n",
       "        [131, 115,  86],\n",
       "        [122, 106,  77]]], dtype=uint8)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#For get the class and location of object detected, \n",
    "# There is a fix index for class, location and confidence\n",
    "# value in @detections array .\n",
    "for i in range(detections.shape[2]):\n",
    "    confidence = detections[0, 0, i, 2] #Confidence of prediction \n",
    "    if confidence > threshold: # Filter prediction \n",
    "        class_id = int(detections[0, 0, i, 1]) # Class label\n",
    "\n",
    "        # Object location \n",
    "        xLeftBottom = int(detections[0, 0, i, 3] * cols) \n",
    "        yLeftBottom = int(detections[0, 0, i, 4] * rows)\n",
    "        xRightTop   = int(detections[0, 0, i, 5] * cols)\n",
    "        yRightTop   = int(detections[0, 0, i, 6] * rows)\n",
    "\n",
    "        xLeftBottom_ = int(widthFactor * xLeftBottom) \n",
    "        yLeftBottom_ = int(heightFactor* yLeftBottom)\n",
    "        xRightTop_   = int(widthFactor * xRightTop)\n",
    "        yRightTop_   = int(heightFactor * yRightTop)\n",
    "        # Draw location of object  \n",
    "        cv2.rectangle(frame_resized, (xLeftBottom, yLeftBottom), (xRightTop, yRightTop),\n",
    "                      (0, 255, 0))\n",
    "\n",
    "        cv2.rectangle(frame_copy, (xLeftBottom_, yLeftBottom_), (xRightTop_, yRightTop_),\n",
    "                      (0, 255, 0),-1)\n",
    "opacity = 0.3\n",
    "cv2.addWeighted(frame_copy, opacity, frame, 1 - opacity, 0, frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person: 0.84372514\n",
      "person: 0.7661178\n"
     ]
    }
   ],
   "source": [
    "for i in range(detections.shape[2]):\n",
    "    confidence = detections[0, 0, i, 2] #Confidence of prediction\n",
    "    if confidence > 0.7 :# Threshold \n",
    "        class_id = int(detections[0, 0, i, 1]) # Class label\n",
    "\n",
    "        # Object location \n",
    "        xLeftBottom = int(detections[0, 0, i, 3] * cols) \n",
    "        yLeftBottom = int(detections[0, 0, i, 4] * rows)\n",
    "        xRightTop   = int(detections[0, 0, i, 5] * cols)\n",
    "        yRightTop   = int(detections[0, 0, i, 6] * rows)\n",
    "\n",
    "        xLeftBottom_ = int(widthFactor * xLeftBottom) \n",
    "        yLeftBottom_ = int(heightFactor* yLeftBottom)\n",
    "        xRightTop_   = int(widthFactor * xRightTop)\n",
    "        yRightTop_   = int(heightFactor * yRightTop)\n",
    "        cv2.rectangle(frame, (xLeftBottom_, yLeftBottom_), (xRightTop_, yRightTop_),\n",
    "          (0, 0, 0),2)\n",
    "        # Draw label and confidence of prediction in frame resized\n",
    "        if class_id in classNames:\n",
    "            label = classNames[class_id] + \": \" + str(confidence)\n",
    "            labelSize, baseLine = cv2.getTextSize(label, cv2.FONT_HERSHEY_TRIPLEX, 0.8, 1)\n",
    "\n",
    "            yLeftBottom_ = max(yLeftBottom_, labelSize[1])\n",
    "            cv2.rectangle(frame, (xLeftBottom_, yLeftBottom_ - labelSize[1]),\n",
    "                                 (xLeftBottom_ + labelSize[0], yLeftBottom_ + baseLine),\n",
    "                                 (255, 255, 255), cv2.FILLED)\n",
    "            cv2.putText(frame, label, (xLeftBottom_, yLeftBottom_),\n",
    "                        cv2.FONT_HERSHEY_TRIPLEX, 0.8, (0, 0, 0))\n",
    "            print(label) #print class and confidence \n",
    "cv2.namedWindow(\"frame\", cv2.WINDOW_NORMAL)\n",
    "cv2.imshow(\"frame\", frame)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
