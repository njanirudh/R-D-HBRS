{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import glob\n",
    "import os\n",
    "from pprint import pprint\n",
    "from pathlib import Path\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "\n",
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mAP\n",
    "\n",
    "Bounding boxes are a crude approximation of many objects. \n",
    "Ground truth boxes :  Box that denote the true position of an object (x,y,width,height).\n",
    "\n",
    "### IoU (Intersection over Union)\n",
    "It is the measure of the ratio between the intersection and the union of the predicted box and the ground truth boxes.[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://tarangshah.com/blog/images/map-7.png\" width=\"300\" height=\"300\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url= \"https://tarangshah.com/blog/images/map-7.png\", width=300, height=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision & Recall\n",
    "\n",
    "True Positive\n",
    "False Positive\n",
    "True Negative\n",
    "False Negative\n",
    "\n",
    "Total Number of Objects\n",
    "\n",
    "Precision : \n",
    "Recall :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'results': [{'bbox': [80, 40, 144, 185], 'label': 'door'},\n",
      "             {'bbox': [34, 6, 67, 55], 'label': 'lamp'}],\n",
      " 'status': True}\n"
     ]
    }
   ],
   "source": [
    "def read_annotation(annotation_path:str):\n",
    "    status = True\n",
    "    \n",
    "    tree = ET.parse(annotation_path)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    all_results = []\n",
    "    for boxes in root.iter('object'):\n",
    "        single_result = {}\n",
    "\n",
    "        filename = root.find('filename').text\n",
    "        class_name = boxes.find('name').text\n",
    "        \n",
    "        ymin, xmin, ymax, xmax = None, None, None, None\n",
    "\n",
    "        for box in boxes.findall(\"bndbox\"):\n",
    "            ymin = int(box.find(\"ymin\").text)\n",
    "            xmin = int(box.find(\"xmin\").text)\n",
    "            ymax = int(box.find(\"ymax\").text)\n",
    "            xmax = int(box.find(\"xmax\").text)\n",
    "\n",
    "        list_with_single_boxes = [xmin, ymin, xmax, ymax]\n",
    "        single_result['label'] = class_name\n",
    "        single_result['bbox'] = list_with_single_boxes\n",
    "        \n",
    "        all_results.append(single_result)\n",
    "\n",
    "    result = {}\n",
    "    result[\"status\"] = status \n",
    "    result[\"results\"] = all_results \n",
    "    \n",
    "    return result\n",
    "\n",
    "result = read_annotation(\"/home/jayasimha/Pictures/door_2.xml\")\n",
    "pprint(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ObjDetector():\n",
    "    def __init__(self, ):\n",
    "        self.graph_def = None\n",
    "        self.out = None\n",
    "    \n",
    "    def initialize_model(pb_path : str):\n",
    "        with tf.gfile.FastGFile(pb_path, 'rb') as f:\n",
    "            graph_def = tf.GraphDef()\n",
    "            graph_def.ParseFromString(f.read())\n",
    "    \n",
    "    def run_detection(img_path :str):\n",
    "        with tf.Session() as sess:\n",
    "            # Restore session\n",
    "            sess.graph.as_default()\n",
    "            tf.import_graph_def(self.graph_def, name='')\n",
    "\n",
    "            # Read and preprocess an image.\n",
    "            img = cv.imread(img_path)\n",
    "            img = cv.resize(img,(480,640))\n",
    "    \n",
    "            rows = img.shape[0]\n",
    "            cols = img.shape[1]\n",
    "            inp = cv.resize(img, (300, 300))\n",
    "            inp = inp[:, :, [2, 1, 0]]  # BGR2RGB\n",
    "\n",
    "            # Run the model\n",
    "            out = sess.run([sess.graph.get_tensor_by_name('num_detections:0'),\n",
    "                            sess.graph.get_tensor_by_name('detection_scores:0'),\n",
    "                            sess.graph.get_tensor_by_name('detection_boxes:0'),\n",
    "                            sess.graph.get_tensor_by_name('detection_classes:0')],\n",
    "                           feed_dict={'image_tensor:0': inp.reshape(1, inp.shape[0], inp.shape[1], 3)})\n",
    "\n",
    "                \n",
    "    \n",
    "    def get_result():\n",
    "        # Visualize detected bounding boxes.\n",
    "        num_detections = int(out[0][0])\n",
    "        for i in range(num_detections):\n",
    "            classId = int(out[3][0][i])\n",
    "            score = float(out[1][0][i])\n",
    "            bbox = [float(v) for v in out[2][0][i]]\n",
    "            if score > 0.3:\n",
    "                x = bbox[1] * cols\n",
    "                y = bbox[0] * rows\n",
    "                right = bbox[3] * cols\n",
    "                bottom = bbox[2] * rows\n",
    "                cv.rectangle(img, (int(x), int(y)), (int(right), int(bottom)), (125, 255, 51), thickness=2)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_object(img_path :str):\n",
    "    status = False\n",
    "    \n",
    "    img = cv2.imread(img_path)\n",
    "    \n",
    "    result = {}\n",
    "    result[\"status\"] = status \n",
    "    result[\"results\"] = []\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bb_intersection_over_union(boxA, boxB):\n",
    "    # determine the (x, y)-coordinates of the intersection rectangle\n",
    "    xA = max(boxA[0], boxB[0])\n",
    "    yA = max(boxA[1], boxB[1])\n",
    "    xB = min(boxA[2], boxB[2])\n",
    "    yB = min(boxA[3], boxB[3])\n",
    "\n",
    "    # compute the area of intersection rectangle\n",
    "    interArea = max(0, xB - xA + 1) * max(0, yB - yA + 1)\n",
    "\n",
    "    # compute the area of both the prediction and ground-truth\n",
    "    # rectangles\n",
    "    boxAArea = (boxA[2] - boxA[0] + 1) * (boxA[3] - boxA[1] + 1)\n",
    "    boxBArea = (boxB[2] - boxB[0] + 1) * (boxB[3] - boxB[1] + 1)\n",
    "\n",
    "    # compute the intersection over union by taking the intersection\n",
    "    # area and dividing it by the sum of prediction + ground-truth\n",
    "    # areas - the interesection area\n",
    "    iou = interArea / float(boxAArea + boxBArea - interArea)\n",
    "\n",
    "    # return the intersection over union value\n",
    "    return iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_accuracy(dataset_path:str):\n",
    "    \n",
    "    img_file_list = glob.glob( dataset_path + \"/*.jpg\", recursive=True)\n",
    "    \n",
    "    for img in img_file_list :\n",
    "        name = Path(img).stem\n",
    "        img_path = dataset_path + name + \".jpg\"\n",
    "        annotation_path = dataset_path + name + \".xml\"\n",
    "\n",
    "        print(img_path,annotation_path)\n",
    "        \n",
    "        detection_result = detect_object(img)\n",
    "        annotation_result = read_annotation(annotation_path)\n",
    "        \n",
    "        bb_1 = detection_result[\"box\"]\n",
    "        bb_2 = annotation_result[\"box\"]\n",
    "        \n",
    "        obj_IoU = bb_intersection_over_union(bb_1,bb_2)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jayasimha/Pictures/door.jpg /home/jayasimha/Pictures/door.xml\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "detect_object() missing 1 required positional argument: 'label'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-4414b109dbae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfind_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/home/jayasimha/Pictures/\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-17-460d28d2e5e1>\u001b[0m in \u001b[0;36mfind_accuracy\u001b[0;34m(dataset_path)\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mannotation_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mdetection_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdetect_object\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mannotation_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_annotation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mannotation_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: detect_object() missing 1 required positional argument: 'label'"
     ]
    }
   ],
   "source": [
    "find_accuracy(\"/home/jayasimha/Pictures/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "\n",
    "1. https://tarangshah.com/blog/2018-01-27/what-is-map-understanding-the-statistic-of-choice-for-comparing-object-detection-models/\n",
    "2. https://www.pyimagesearch.com/2016/11/07/intersection-over-union-iou-for-object-detection/\n",
    "3. http://homepages.inf.ed.ac.uk/ckiw/postscript/ijcv_voc09.pdf\n",
    "4. http://cocodataset.org/#detection-eval\n",
    "5. https://stackoverflow.com/questions/53317592/reading-pascal-voc-annotations-in-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
