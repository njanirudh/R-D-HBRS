{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import glob\n",
    "import os\n",
    "import csv\n",
    "from pprint import pprint\n",
    "from pathlib import Path\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML\n",
    "\n",
    "# Remove numpy warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mAP\n",
    "\n",
    "Bounding boxes are a crude approximation of many objects. \n",
    "Ground truth boxes :  Box that denote the true position of an object (x,y,width,height).\n",
    "\n",
    "### IoU (Intersection over Union)\n",
    "It is the measure of the ratio between the intersection and the union of the predicted box and the ground truth boxes.[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://tarangshah.com/blog/images/map-7.png\" width=\"300\" height=\"300\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url= \"https://tarangshah.com/blog/images/map-7.png\", width=300, height=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision & Recall\n",
    "\n",
    "True Positive\n",
    "False Positive\n",
    "True Negative\n",
    "False Negative\n",
    "\n",
    "Total Number of Objects\n",
    "\n",
    "Precision : \n",
    "Recall :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/jayasimha/Pictures/door_2.xml'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-5a336f30135b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_annotation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/home/jayasimha/Pictures/door_2.xml\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0mpprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-5a336f30135b>\u001b[0m in \u001b[0;36mread_annotation\u001b[0;34m(annotation_path)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mstatus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mtree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mET\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mannotation_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetroot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/xml/etree/ElementTree.py\u001b[0m in \u001b[0;36mparse\u001b[0;34m(source, parser)\u001b[0m\n\u001b[1;32m   1195\u001b[0m     \"\"\"\n\u001b[1;32m   1196\u001b[0m     \u001b[0mtree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mElementTree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1197\u001b[0;31m     \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1198\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/xml/etree/ElementTree.py\u001b[0m in \u001b[0;36mparse\u001b[0;34m(self, source, parser)\u001b[0m\n\u001b[1;32m    585\u001b[0m         \u001b[0mclose_source\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    586\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"read\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 587\u001b[0;31m             \u001b[0msource\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    588\u001b[0m             \u001b[0mclose_source\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    589\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/jayasimha/Pictures/door_2.xml'"
     ]
    }
   ],
   "source": [
    "def read_annotation(annotation_path:str):\n",
    "    status = True\n",
    "    \n",
    "    tree = ET.parse(annotation_path)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    all_results = []\n",
    "    for boxes in root.iter('object'):\n",
    "        single_result = {}\n",
    "\n",
    "        filename = root.find('filename').text\n",
    "        class_name = boxes.find('name').text\n",
    "        \n",
    "        ymin, xmin, ymax, xmax = None, None, None, None\n",
    "\n",
    "        for box in boxes.findall(\"bndbox\"):\n",
    "            ymin = int(box.find(\"ymin\").text)\n",
    "            xmin = int(box.find(\"xmin\").text)\n",
    "            ymax = int(box.find(\"ymax\").text)\n",
    "            xmax = int(box.find(\"xmax\").text)\n",
    "\n",
    "        list_with_single_boxes = (xmin, ymin, xmax, ymax)\n",
    "        single_result['label'] = class_name\n",
    "        single_result['bbox'] = list_with_single_boxes\n",
    "        \n",
    "        all_results.append(single_result)\n",
    "\n",
    "    result = {}\n",
    "    result[\"status\"] = status \n",
    "    result[\"results\"] = all_results \n",
    "    \n",
    "    return result\n",
    "\n",
    "result = read_annotation(\"/home/jayasimha/Pictures/door_2.xml\")\n",
    "pprint(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ObjDetector():\n",
    "    def __init__(self):\n",
    "        self.graph_def = None\n",
    "        self.out = None\n",
    "        self.img = None\n",
    "        self.labels = {}\n",
    "        \n",
    "        self.rows = 0\n",
    "        self.cols = 0\n",
    "    \n",
    "    def initialize_model(self,pb_path:str):\n",
    "        with tf.gfile.GFile(pb_path, 'rb') as f:\n",
    "            self.graph_def = tf.GraphDef()\n",
    "            self.graph_def.ParseFromString(f.read())\n",
    "            \n",
    "    def set_labels(self,path:str):\n",
    "        with open(path, 'r') as csvFile:\n",
    "            reader = csv.reader(csvFile)\n",
    "            for i,row in enumerate(reader):\n",
    "                self.labels[i+1] = row[-1]\n",
    "        csvFile.close()\n",
    "    \n",
    "    def run_detection(self,img_path:str):\n",
    "        with tf.Session() as sess:\n",
    "            # Restore session\n",
    "            sess.graph.as_default()\n",
    "            tf.import_graph_def(self.graph_def, name='')\n",
    "\n",
    "            # Read and preprocess an image.\n",
    "            self.img = cv2.imread(img_path)\n",
    "            self.img = cv2.resize(self.img,(480,640))\n",
    "    \n",
    "            self.rows = self.img.shape[0]\n",
    "            self.cols = self.img.shape[1]\n",
    "            inp = cv2.resize(self.img, (300, 300))\n",
    "            inp = inp[:, :, [2, 1, 0]]  # BGR2RGB\n",
    "\n",
    "            # Run the model\n",
    "            self.out = sess.run([sess.graph.get_tensor_by_name('num_detections:0'),\n",
    "                            sess.graph.get_tensor_by_name('detection_scores:0'),\n",
    "                            sess.graph.get_tensor_by_name('detection_boxes:0'),\n",
    "                            sess.graph.get_tensor_by_name('detection_classes:0')],\n",
    "                           feed_dict={'image_tensor:0': inp.reshape(1, inp.shape[0], inp.shape[1], 3)})\n",
    "        \n",
    "        return self\n",
    "                \n",
    "    \n",
    "    def get_result(self):\n",
    "        status = True\n",
    "        \n",
    "        all_results = []\n",
    "        # Visualize detected bounding boxes.\n",
    "        num_detections = int(self.out[0][0])\n",
    "        for i in range(num_detections):\n",
    "            single_result = {}\n",
    "\n",
    "            classId = int(self.out[3][0][i])\n",
    "            score = float(self.out[1][0][i])\n",
    "            bbox = [float(v) for v in self.out[2][0][i]]\n",
    "            if score > 0.3:\n",
    "                x = int(bbox[1] * self.cols)\n",
    "                y = int(bbox[0] * self.rows)\n",
    "                right = int(bbox[3] * self.cols)\n",
    "                bottom = int(bbox[2] * self.rows)\n",
    "                                \n",
    "                single_result['label'] = self.labels[classId]\n",
    "                single_result['bbox'] = (x,y,x+right,y+bottom)\n",
    "                \n",
    "                all_results.append(single_result)\n",
    "                \n",
    "        result = {}\n",
    "        result[\"status\"] = status \n",
    "        result[\"results\"] = all_results\n",
    "    \n",
    "        return result\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bbox_for_label(json:str,label:str):\n",
    "    result_list = json[\"results\"]\n",
    "    \n",
    "    for val in result_list:\n",
    "        if val[\"label\"] == label:\n",
    "            return val[\"bbox\"]\n",
    "        else:\n",
    "            return (0,0,0,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bb_intersection_over_union(boxA, boxB):\n",
    "    # determine the (x, y)-coordinates of the intersection rectangle\n",
    "    xA = max(boxA[0], boxB[0])\n",
    "    yA = max(boxA[1], boxB[1])\n",
    "    xB = min(boxA[2], boxB[2])\n",
    "    yB = min(boxA[3], boxB[3])\n",
    "\n",
    "    # compute the area of intersection rectangle\n",
    "    interArea = max(0, xB - xA + 1) * max(0, yB - yA + 1)\n",
    "\n",
    "    # compute the area of both the prediction and ground-truth\n",
    "    # rectangles\n",
    "    boxAArea = (boxA[2] - boxA[0] + 1) * (boxA[3] - boxA[1] + 1)\n",
    "    boxBArea = (boxB[2] - boxB[0] + 1) * (boxB[3] - boxB[1] + 1)\n",
    "\n",
    "    # compute the intersection over union by taking the intersection\n",
    "    # area and dividing it by the sum of prediction + ground-truth\n",
    "    # areas - the interesection area\n",
    "    iou = interArea / float(boxAArea + boxBArea - interArea)\n",
    "\n",
    "    # return the intersection over union value\n",
    "    return iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TF_MODEL_PATH = \"/home/nj/NJ/Models/faster_rcnn_inception_resnet_v2_atrous_oid_v4_2018_12_12/frozen_inference_graph.pb\"\n",
    "MODEL_LABEL_PATH = \"/home/nj/NJ/Models/faster_rcnn_inception_resnet_v2_atrous_oid_v4_2018_12_12/class-descriptions-boxable.csv\"\n",
    "\n",
    "DATASET_PATH = \"/home/jayasimha/Pictures/Datasets/Doors\" \n",
    "\n",
    "obj_detector = ObjDetector()\n",
    "obj_detector.initialize_model(TF_MODEL_PATH)\n",
    "obj_detector.set_labels(MODEL_LABEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'DATASET_PATH' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-f508dfd8c1ce>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mimg_file_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mDATASET_PATH\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/*.jpg\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursive\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mDOOR_TRUE_POSITIVE\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mDOOR_FALSE_POSITIVE\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mDOOR_TOTAL\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mHANDLE_TRUE_POSITIVE\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mHANDLE_FALSE_POSITIVE\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mHANDLE_TOTAL\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'DATASET_PATH' is not defined"
     ]
    }
   ],
   "source": [
    "img_file_list = glob.glob( DATASET_PATH + \"/*.jpg\", recursive=True)\n",
    "\n",
    "DOOR_TRUE_POSITIVE , DOOR_FALSE_POSITIVE ,DOOR_TOTAL  = 0 , 0 , 0\n",
    "HANDLE_TRUE_POSITIVE , HANDLE_FALSE_POSITIVE , HANDLE_TOTAL = 0 , 0 , 0\n",
    "\n",
    "IOU_threshold = 0.5\n",
    "for img in img_file_list :\n",
    "    name = Path(img).stem\n",
    "    img_path = os.path.join(DATASET_PATH , name + \".jpg\")\n",
    "    annotation_path = os.path.join(DATASET_PATH , name + \".xml\")\n",
    "\n",
    "    print(img_path,\" <---> \",annotation_path)\n",
    "        \n",
    "    detection_result = obj_detector.run_detection(img).get_result()\n",
    "    annotation_result = read_annotation(annotation_path)\n",
    "    \n",
    "    print(detection_result)\n",
    "    print(annotation_result)\n",
    "        \n",
    "    # IoU for \"Door\" \n",
    "    # --------------------------------------------------------------\n",
    "    door_detection_bbox = get_bbox_for_label(detection_result,\"Door\")\n",
    "    door_annotation_bbox = get_bbox_for_label(annotation_result,\"door\")\n",
    "    \n",
    "    door_single_IoU = bb_intersection_over_union(door_detection_bbox,door_annotation_bbox)\n",
    "    print(door_single_IoU)\n",
    "    \n",
    "    if door_single_IoU > IOU_threshold :\n",
    "        DOOR_TRUE_POSITIVE += 1\n",
    "    else:\n",
    "        DOOR_FALSE_POSITIVE += 1\n",
    "    \n",
    "    # IoU for \"Door\" \n",
    "    # --------------------------------------------------------------\n",
    "    handle_detection_bbox = get_bbox_for_label(detection_result,\"Door handle\")\n",
    "    handle_annotation_bbox = get_bbox_for_label(annotation_result,\"Door handle\")\n",
    "    \n",
    "    handle_single_IoU = bb_intersection_over_union(handle_detection_bbox,handle_annotation_bbox)\n",
    "    if handle_single_IoU > IOU_threshold1 :\n",
    "        HANDLE_TRUE_POSITIVE += 1\n",
    "    else:\n",
    "        HANDLE_FALSE_POSITIVE += 1\n",
    "    \n",
    "#     out_img = cv2.imread(img_path)\n",
    "#     cv2.rectangle(out_img,(door_detection_bbox[0], door_detection_bbox[1]),\n",
    "#                   (door_detection_bbox[2], door_detection_bbox[3]),(255,255,0),2)\n",
    "#     cv2.rectangle(out_img,(door_annotation_bbox[0], door_annotation_bbox[1]),\n",
    "#                   (door_annotation_bbox[2], door_annotation_bbox[3]),(255,0,0),2)\n",
    "#     cv2.rectangle(out_img,(handle_detection_bbox[0], handle_detection_bbox[1]),\n",
    "#                   (handle_detection_bbox[2], handle_detection_bbox[3]),(255,255,0),2)\n",
    "#     cv2.rectangle(out_img,(door_annotation_bbox[0], door_annotation_bbox[1]),\n",
    "#                   (door_annotation_bbox[2], door_annotation_bbox[3]),(255,0,0),2)\n",
    "    \n",
    "#     plt.imshow(out_img)\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Door calculations\n",
    "DOOR_PRECISION  = (DOOR_TRUE_POSITIVE)/(DOOR_TRUE_POSITIVE + DOOR_FALSE_POSITIVE)\n",
    "DOOR_RECALL = (DOOR_TRUE_POSITIVE)/(DOOR_TOTAL)\n",
    "\n",
    "# Handle calculations\n",
    "HANDLE_PRECISION = (HANDLE_TRUE_POSITIVE)/(HANDLE_TRUE_POSITIVE + HANDLE_FALSE_POSITIVE)\n",
    "HANDLE_RECALL = (HANDLE_TRUE_POSITIVE)/(HANDLE_TOTAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'DOOR_PRECISION' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-0f3be4fa7ac2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmAP\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mDOOR_PRECISION\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mHANDLE_PRECISION\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mAP of the detection model : '\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmAP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'DOOR_PRECISION' is not defined"
     ]
    }
   ],
   "source": [
    "mAP = (DOOR_PRECISION + HANDLE_PRECISION)/2\n",
    "print('mAP of the detection model : ',mAP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "\n",
    "1. https://tarangshah.com/blog/2018-01-27/what-is-map-understanding-the-statistic-of-choice-for-comparing-object-detection-models/\n",
    "2. https://www.pyimagesearch.com/2016/11/07/intersection-over-union-iou-for-object-detection/\n",
    "3. http://homepages.inf.ed.ac.uk/ckiw/postscript/ijcv_voc09.pdf\n",
    "4. http://cocodataset.org/#detection-eval\n",
    "5. https://stackoverflow.com/questions/53317592/reading-pascal-voc-annotations-in-python\n",
    "6. https://medium.com/@jonathan_hui/map-mean-average-precision-for-object-detection-45c121a31173"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
